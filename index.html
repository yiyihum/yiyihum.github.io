<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WS1J1K9PZM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WS1J1K9PZM');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Yiming Huang | Homepage</title>
  
  <meta name="author" content="Yiming Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒŸ</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:20px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yiming Huang é»„å¿†é“­</name>
              </p>
              <p>
                Hi, I'm Yimi ðŸ‘‹<br><br> 
                I'm currently having fun as a research intern at TikTok, where I work with Dr. <a href="https://siviltaram.github.io/">Qian Liu</a>. Before this, I spent exciting long time at Microsoft Research Asia, working with Dr. <a href="https://xiaoliunlc.github.io/">Xiao Liu</a>, Dr. <a href="https://scholar.google.com/citations?user=piUkwMYAAAAJ&hl=en">Yeyun Gong</a>, and Dr. <a href="https://scholar.google.com/citations?user=LG_E-4EAAAAJ&hl=en">Weizhu Chen</a>.<br><br> 

                I'll soon be joining UCSD as a PhD student under Prof. Jingbo Shang's guidance! ðŸŽ“âœ¨
              </p>

              <p>
                My research focuses on:<br>
                (1) evaluating and enhancing the reasoning capabilities of large language models, particularly in <strong>math, code, and agent</strong> tasks;<br>
                (2) exploring <strong>data-centric methods</strong>  to improve learning efficiency and adaptability.<br>
              </p>
              <!-- <p>
                In the future, I aim to creating more efficient, adaptable, and reliable LMs and agents.
              </p> -->

              <!-- <p>
                My research interests lie in two main directions:
              <br>
                <strong>(1) LM Agents in Complex Interactive Environments</strong><br>
                I wish to focus my future work on creating more efficient, adaptable, and reliable LM agents. 
                One promising direction is enabling agents to autonomously adapt to new environments filled with unseen tasks. 
                Another critical direction is enabling agents to detect malicious actions and ensure they pose no harm to users or society.
              <br>
                <strong>(2) Data Synthesis and Data Selection</strong><br>
                I aim to explore data-centric methods to improve learning efficiency and adaptability, leading to a series of profound questions:
                <li>How do we define, combine, and re-weight multiple domains of data during pretraining?</li>
                <li>How do we identify "difficult" data for a given model, a crucial step in enabling its iterative self-improvement?</li>
                <li>What is the best way to represent knowledge? How can a concept be grounded across various modalities, such as text, images, videos, and interactive sensory experiences?</li>
              </p> -->



      
              <p style="text-align:left">
                    <a href="mailto:yeeelow233@gmail.com"><img src="images/mail.svg" alt="Email" style="vertical-align:middle;" width="24" height="24"></a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=L8E-ccakgcQC&hl=en&oi=sra"><img src="images/google-scholar.svg" alt="Google Scholar" style="vertical-align:middle;" width="24" height="24"></a> &nbsp/&nbsp
                    <a href="https://x.com/yeeelow233"><img src="images/twitter.svg" alt="Twitter" style="vertical-align:middle;" width="30" height="30"></a> &nbsp/&nbsp
                    <a href="https://github.com/yiyihum"><img src="images/github-alt.svg" alt="Twitter" style="vertical-align:middle;" width="24" height="24"></a>
              </p>
            </td>
            <td style="padding:2.5%;width:60%;max-width:60%">
              <a href="images/yimih.jpeg"><img style="width:70%;max-width:70%" alt="profile photo" src="images/yimih.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2501.13629">
              <papertitle>Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models</papertitle>
            </a>
            <br>MSRA AIR Team
            <br>
            <strong><em>AAAI</em></strong>, 2025
            <br>
          </td>
        </tr>
        
        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2502.14848">
              <papertitle>GATE: Graph-based Adaptive Tool Evolution Across Diverse Tasks</papertitle>
            </a>
            <br>Jianwen Luo*, <strong>Yiming Huang*</strong>, Jinxiang Meng, Fangyu Lei, Shizhu He, Xiao Liu, Shanshan Jiang, Bin Dong, Jun Zhao, Kang Liu
            <br>
            <strong><em>AAAI</em></strong>, 2025
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2403.02333">
              <papertitle>Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning</papertitle>
            </a>
            <br>
              <strong>Yiming Huang</strong>, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, Weizhu Chen
            <br>
            <strong><em>AAAI</em></strong>, 2025
            <br>
          </td>
        </tr>
        
        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://da-code-bench.github.io">
              <papertitle>DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models</papertitle>
            </a>
            <br>
              <strong>Yiming Huang*</strong>, Jianwen Luo*, Yan Yu, Yitong Zhang, Yifan Wei, Shizhu He, Lifu Huang, Xiao Liu, Jun Zhao, Kang Liu
            <br>
            <strong><em>EMNLP</em></strong>, 2024
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2312.02143">
              <papertitle>Competition-level Problems Are Effective LLM Evaluators</papertitle>
            </a>
            <br>
            <strong>Yiming Huang*</strong>, Zhenghao Lin*, Xiao Liu, Yeyun Gong, Shuai Lu, Fangyu Lei, Yaobo Liang, Yelong Shen, Chen Lin, Nan Duan, Weizhu Chen
            <br>
            <strong><em>ACL</em></strong>, 2024
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2310.15147">
              <papertitle>S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models</papertitle>
            </a>
            <br>
            Fangyu Lei*, Qian Liu*, <strong>Yiming Huang*</strong>, Shizhu He, Jun Zhao, Kang Liu
            <br>
            <strong><em>NAACL</em></strong>, 2024
            <br>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2305.11725">
              <papertitle>S3HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering</papertitle>
            </a>
            <br>
            Fangyu Lei, Shizhu He, Xiang Li, Yifan Wei, <strong>Yiming Huang</strong>, Jun Zhao, Kang Liu
            <br>
            <strong><em>ACL</em></strong>, 2023
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2308.15280">
              <papertitle>ADFA: Attention-Augmented Differentiable Top-k Feature Adaptation for Unsupervised Medical Anomaly Detection</papertitle>
            </a>
            <br>
            <strong>Yiming Huang</strong>, Guole Liu, Yaoru Luo, Ge Yang
            <br>
            <strong><em>ICIP</em></strong>, 2023
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://papers.bmvc2023.org/0084.pdf">
              <papertitle>Spatial and Planar Consistency for Semi-Supervised Volumetric Medical Image Segmentation</papertitle>
            </a>
            <br>
            Yanfeng Zhou, <strong>Yiming Huang</strong>, Ge Yang
            <br>
            <strong><em>BMVC</em></strong>, 2023
            <br>
          </td>
        </tr>

      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            <p>
              <li>USTB Principal Medal (10 out of all undergraduate graduates, highest honor of undergraduate student), 2023</li>
              <li>Beijing Outstanding Graduate Awards (top 1% in Academics), 2023</li>
              <li>National Scholarship (Top 0.2% nationwide), 2022</li>
              <li>National Scholarship (Top 0.2% nationwide), 2021</li>
              <li>National Scholarship (Top 0.2% nationwide), 2020</li>
            </p >
          </td>
        </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>













